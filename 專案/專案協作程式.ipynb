{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "專案股市資料爬蟲及整理程式\n",
    "股市資料爬蟲及整理:\n",
    "1. 再次從經濟日報個別網址的爬蟲中獲得日期、標題以及內容(刻意同時在兩程式同時爬蟲~讓主程式能往下一步做\n",
    "2. 從台灣證交所爬取股市資料\n",
    "3. 從yahoo獲得國外資料\n",
    "4. 將情緒分數資料與日期、股票資料整合在一起\n",
    "5. 將有用資料存成pickle，供回歸分析使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從本機csv匯入經濟日報網址list，並且在去除重複網址後，才進行個別網址的爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://money.udn.com/money/story/5641/3238080\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "c_l = [\"2\",\"3\",\"4\",\"5\"]\n",
    "udn_a_href_list_news_addr_short =  []\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報貿易戰新聞網址.csv'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "for y in range(53129):\n",
    "    udn_a_href_list_news_addr_short.append(sheet_1.cell_value(rowx=y,colx=0))\n",
    "for i in c_l:\n",
    "    file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報貿易戰新聞網址'+i+'.csv'\n",
    "    book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "    sheet_1 = book_r.sheet_by_index(0)\n",
    "    for y in range(65529):\n",
    "        udn_a_href_list_news_addr_short.append(sheet_1.cell_value(rowx=y,colx=0))\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報貿易戰新聞網址6.csv'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "for y in range(46089):\n",
    "    udn_a_href_list_news_addr_short.append(sheet_1.cell_value(rowx=y,colx=0))\n",
    "add_adr_lis = ['https://money.udn.com/money/story/5641/3239099', 'https://money.udn.com/money/story/5641/3239067', 'https://money.udn.com/money/story/5641/3238927', 'https://money.udn.com/money/story/5641/3238916', 'https://money.udn.com/money/story/5641/3238733', 'https://money.udn.com/money/story/5641/3238690', 'https://money.udn.com/money/story/5641/3238527', 'https://money.udn.com/money/story/5641/3238522', 'https://money.udn.com/money/story/5641/3238515', 'https://money.udn.com/money/story/5641/3238503', 'https://money.udn.com/money/story/5641/3238418', 'https://money.udn.com/money/story/5641/3238360', 'https://money.udn.com/money/story/8888/3834338', 'https://money.udn.com/money/story/8888/3834346', 'https://money.udn.com/money/story/5641/3238359', 'https://money.udn.com/money/story/5641/3238349', 'https://money.udn.com/money/story/5641/3238338', 'https://money.udn.com/money/story/5641/3238336', 'https://money.udn.com/money/story/5641/3238315', 'https://money.udn.com/money/story/5641/3238310', 'https://money.udn.com/money/story/5641/3238248', 'https://money.udn.com/money/story/5641/3238233', 'https://money.udn.com/money/story/5641/3238103', 'https://money.udn.com/money/story/5641/3238080', 'https://money.udn.com/money/story/8888/3834338', 'https://money.udn.com/money/story/8888/3834346']\n",
    "for u in add_adr_lis:\n",
    "    udn_a_href_list_news_addr_short.append(u)\n",
    "print(udn_a_href_list_news_addr_short[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從個別網址的爬蟲中獲得日期、標題以及內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests, json, csv, datetime\n",
    "import re\n",
    "from xlrd import *\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from xlwt import *\n",
    "udn_a_href_list_news_addr_short_new=[]\n",
    "file_r = \"C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報貿易戰新聞網址新.csv\"\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "for t in range(3083):\n",
    "    udn_a_href_list_news_addr_short_new.append(sheet_1.cell_value(rowx=t,colx=0))\n",
    "row = 0\n",
    "file = Workbook(encoding = 'utf-8')\n",
    "#指定file以utf-8的格式打开\n",
    "table = file.add_sheet('文字內容')\n",
    "udn_adr_a_list_o_title = []\n",
    "udn_adr_a_list_o_description = []\n",
    "udn_adr_a_list_o_date = []    \n",
    "print(\"check p 1\")\n",
    "print(len(udn_a_href_list_news_addr_short_new))\n",
    "print(udn_a_href_list_news_addr_short_new)\n",
    "try:\n",
    "    for adr in udn_a_href_list_news_addr_short_new:\n",
    "        #time.sleep(1)\n",
    "        udn_adr_res = requests.get(adr,verify = False)\n",
    "        udn_adr_res.encoding = \"UTF-8\"\n",
    "        udn_adr_soup = BeautifulSoup(udn_adr_res.text)\n",
    "        #print(udn_adr_soup)\n",
    "        udn_adr_a_find_title = udn_adr_soup.find_all(\"meta\",property=\"og:title\")\n",
    "        udn_adr_a_list_o_title.append(udn_adr_a_find_title[0]['content'])\n",
    "        udn_adr_a_find_description = udn_adr_soup.find_all(\"meta\",attrs={'name':\"description\"})\n",
    "        udn_adr_a_list_o_description.append(udn_adr_a_find_description[0]['content'])\n",
    "        udn_adr_a_find_date = udn_adr_soup.find_all(\"meta\",attrs={'name':\"date\"})\n",
    "        table.write(row,0,udn_adr_a_find_date[0]['content'])\n",
    "        table.write(row,1,udn_adr_a_find_title[0]['content'])\n",
    "        table.write(row,2,udn_adr_a_find_description[0]['content'])\n",
    "        row +=1\n",
    "        #print(row)\n",
    "    print(udn_adr_a_list_o_title[-3])\n",
    "    print(udn_adr_a_list_o_description[-3])\n",
    "    print(udn_adr_a_list_o_date[-3])\n",
    "    file.save('C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報文字內容2.csv')\n",
    "except BaseException:\n",
    "    file.save('C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報文字內容2.csv')\n",
    "    print(udn_adr_a_list_o_title)\n",
    "    print(udn_adr_a_list_o_description)\n",
    "    print(udn_adr_a_list_o_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(udn_adr_a_list_o_description)\n",
    "#print(udn_adr_a_list_o_title)\n",
    "print(len(udn_adr_a_list_o_description))\n",
    "print(udn_adr_a_list_o_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(udn_a_href_list_news_addr_short_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlwt import *\n",
    "from xlrd import *\n",
    "row_1 = 0\n",
    "file1 = Workbook(encoding = 'utf-8')\n",
    "table1 = file1.add_sheet('文字內容')\n",
    "for u in udn_a_href_list_news_addr_short_new:\n",
    "    table1.write(row_1,0,u)\n",
    "    row_1 += 1      \n",
    "#print(udn_a_href_list_news_addr)\n",
    "file1.save('C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報貿易戰新聞網址新.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將經濟日報文字內容存成pickle檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlrd import *\n",
    "from xlwt import *\n",
    "import pickle\n",
    "all_udn_news_data_dict = {'date':[],'title':[],'summary':[]}\n",
    "file_r = \"C:\\\\Users\\\\Will\\\\Desktop\\\\經濟日報文字內容2.csv\"\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "for t in range(3083):\n",
    "    all_udn_news_data_dict['date'].append(sheet_1.cell_value(rowx=t,colx=0))\n",
    "for t in range(3083):\n",
    "    all_udn_news_data_dict['title'].append(sheet_1.cell_value(rowx=t,colx=1))\n",
    "for t in range(3083):\n",
    "    all_udn_news_data_dict['summary'].append(sheet_1.cell_value(rowx=t,colx=2))\n",
    "file = open('經濟日報內容.pickle', 'wb')\n",
    "pickle.dump(all_udn_news_data_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('經濟日報內容.pickle', 'rb') as file:\n",
    "    a_dict1 =pickle.load(file)\n",
    "\n",
    "print(a_dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "外國股票資料爬取，利用pandas_datareader找美國著名的指數型etf及重要國際企業\n",
    "透過pandas_datareader從yahoo找'SPY','AGG','UUP','VNQ','GLD','VDC','VDE','VFH','VIS','VAW','VGT','VOX'的股市資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "start = datetime.datetime(2016, 6, 1)\n",
    "end = datetime.datetime(2019, 6, 4)\n",
    "list = ['^GSPC','USD']\n",
    "list_etf = ['SPY','AGG','UUP','VNQ','GLD','VDC','VDE','VFH','VIS','VAW','VGT','VOX']\n",
    "today = '20190331'\n",
    "tckr1 = '^GSPC'\n",
    "# ETF data\n",
    "for i in range(len(list_etf)):\n",
    "    data = web.DataReader(list_etf[i], 'yahoo', start, end)\n",
    "    file_name = '美國etf_'+str(list_etf[i])+'.pickle'\n",
    "    file = open(file_name, 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "    sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, csv\n",
    "import re\n",
    "import time\n",
    "from xlwt import *\n",
    "import sys\n",
    "import requests, json, csv, datetime\n",
    "from xlrd import *\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "#import xlwt\n",
    "#import xlwt\n",
    "#指定file以utf-8的格式打开\n",
    "col = 0\n",
    "row = 1\n",
    "m = 0\n",
    "# ,'元大電子0053','富邦科技0052','富邦金融0059','台積電2330','鴻海2317','南亞1303','台塑1301','國泰金2882'\n",
    "stock_name_list = ['元大台灣0050']\n",
    "stock_num_list = ['0050']\n",
    "year_count_list = ['2018']\n",
    "month_count_list = ['06','07','08','09','10','11','12']\n",
    "spe_2019_month_count_list = ['01','02','03','04','05']\n",
    "fields = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "for y in range(len(stock_num_list)):\n",
    "    row = 1\n",
    "    file = Workbook(encoding = 'utf-8')\n",
    "    table = file.add_sheet(str(stock_name_list[y]), cell_overwrite_ok=True)\n",
    "    stock_num = stock_num_list[y]\n",
    "    for m in range(9):\n",
    "        table.write(row,m,fields[m])\n",
    "        transaction_amount = []\n",
    "        total_data_list = []\n",
    "        change_list = []\n",
    "        date_list = []\n",
    "    for year_count in year_count_list:\n",
    "        for month_count in month_count_list:\n",
    "            time.sleep(6)\n",
    "            url_twse = 'http://www.tse.com.tw/exchangeReport/STOCK_DAY?response=json&date=' + str(year_count) + str(month_count) +  '01&stockNo='+ str(stock_num) + '&_=1533353379536'\n",
    "            res = requests.get(url_twse)\n",
    "            s = json.loads(res.text)\n",
    "            if s['stat'] == \"OK\":\n",
    "                for data in (s['data']):\n",
    "                    row += 1\n",
    "                    total_data_list.append(data)\n",
    "                    #change_list.append(data[7])\n",
    "                    if \",\" in data[8]:\n",
    "                        data[8] = data[8].replace(\",\",\"\")\n",
    "                        #transaction_amount.append(float(data[8]))\n",
    "                    else:\n",
    "                        transaction_amount.append(float(data[8]))\n",
    "                        #date_list.append(data[0])\n",
    "                    for j in range(9):\n",
    "                        table.write(row,j,data[j])\n",
    "            #print(stock_num,year_count,month_count)\n",
    "    for month_count in spe_2019_month_count_list:\n",
    "        time.sleep(6)\n",
    "        url_twse = 'http://www.tse.com.tw/exchangeReport/STOCK_DAY?response=json&date=2019'+ str(month_count) +  '01&stockNo='+ str(stock_num) + '&_=1533353379536'\n",
    "        res = requests.get(url_twse)\n",
    "        s = json.loads(res.text)\n",
    "        if s['stat'] == \"OK\":\n",
    "            for data in (s['data']):\n",
    "                row += 1\n",
    "                total_data_list.append(data)\n",
    "                #change_list.append(data[7])\n",
    "                if \",\" in data[8]:\n",
    "                    data[8] = data[8].replace(\",\",\"\")\n",
    "                        #transaction_amount.append(float(data[8]))\n",
    "                else:\n",
    "                    transaction_amount.append(float(data[8]))\n",
    "                        #date_list.append(data[0])\n",
    "                for j in range(9):\n",
    "                    table.write(row,j,data[j])\n",
    "        #print(stock_num,'2019',month_count)\n",
    "    file_name = 'C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\個股資料'+stock_name_list[y]+'.csv'\n",
    "    #file_name = 'C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\個股資料.csv'\n",
    "    file.save(file_name)\n",
    "\n",
    "import xlrd\n",
    "import pickle\n",
    "t_l = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\個股資料元大台灣0050.csv'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "all_stock_d={}\n",
    "for i in range(len(t_l)):\n",
    "        all_stock_d[t_l[i]]= []\n",
    "for b in range(len(t_l)):\n",
    "    for r in range(246):\n",
    "        if sheet_1.cell_value(rowx=r,colx=0) != \"\":\n",
    "            all_stock_d[t_l[b]].append(sheet_1.cell_value(rowx=r,colx=b))\n",
    "        else:\n",
    "            break\n",
    "file_name = '股票資料ETF0050.pickle'\n",
    "file = open(file_name, 'wb')\n",
    "pickle.dump(all_stock_d, file)\n",
    "file.close()\n",
    "\n",
    "import pickle\n",
    "stock_name_list = ['元大台灣0050']\n",
    "stock_num_list = ['0050']\n",
    "adr_l = []\n",
    "for y in range(len(stock_name_list)):\n",
    "    adr_l.append('C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\股票資料ETF0050.pickle')\n",
    "for i in range(len(stock_name_list)):\n",
    "    with open(adr_l[i], 'rb') as file:\n",
    "        a_dict1 =pickle.load(file)\n",
    "        all_stock_dict[stock_num_list[i]] = a_dict1\n",
    "\n",
    "#------------根據情緒分數清單，製作時間dict \n",
    "#{'2018-07-07': {'emotion_score': 4.0, '0054': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0053': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0052': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0059': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2330': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '1303': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '1301': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2882': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2317': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}}, \n",
    "import xlrd\n",
    "import datetime,time\n",
    "avai_date_list = []\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\情緒分數.xlsx'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "start='2018-07-02'\n",
    "end='2019-06-05'\n",
    "non_exsit_date_stock_dict = {} #沒有情緒分數\n",
    "datestart=datetime.datetime.strptime(start,'%Y-%m-%d')\n",
    "dateend=datetime.datetime.strptime(end,'%Y-%m-%d')\n",
    "stock_name_list = ['元大台灣0050']\n",
    "stock_num_list = ['0050']\n",
    "t_l = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "while datestart<dateend:\n",
    "    datestart+=datetime.timedelta(days=1)\n",
    "    date = datestart.strftime('%Y-%m-%d')\n",
    "    if date in emotion_date_list:\n",
    "        for i in range(1,327):\n",
    "            date1 = datetime.datetime.utcfromtimestamp((sheet_1.cell_value(rowx=i,colx=0)-25569)*86400)\n",
    "            date1 = date1.strftime('%Y-%m-%d')\n",
    "            if date ==date1:\n",
    "                avai_date_list.append(date)\n",
    "                date_stock_dict[date] = {'emotion_score':float(sheet_1.cell_value(rowx=i,colx=1))}\n",
    "                for u in stock_num_list:\n",
    "                    date_stock_dict[date][u] = {\"成交股數\":'0',\"開盤價\":'0',\"收盤價\":'0',\"漲跌價差\":'0',\"成交筆數\":'0'}\n",
    "    else:\n",
    "        non_exsit_date_stock_dict[date] = {}\n",
    "print(len(avai_date_list))\n",
    "# print(date[-1],date[-2],type(date[-3]))\n",
    "# print(date_stock_dict)\n",
    "print(len(date_stock_dict))\n",
    "\n",
    "stock_name_list = ['元大台灣0050']\n",
    "stock_num_list = ['0050']\n",
    "for r in stock_num_list:\n",
    "    for u in range(len(all_stock_dict[r][\"日期\"])):\n",
    "        all_stock_dict[r][\"日期\"][u] = str(all_stock_dict[r][\"日期\"][u]).replace('/','-',2)\n",
    "        all_stock_dict[r][\"日期\"][u] = str(all_stock_dict[r][\"日期\"][u]).replace('107','2018')\n",
    "        all_stock_dict[r][\"日期\"][u] = str(all_stock_dict[r][\"日期\"][u]).replace('108','2019')\n",
    "        #print(all_stock_dict[r][\"日期\"][u])\n",
    "for r in stock_num_list:\n",
    "    for u in range(len(avai_date_list)):\n",
    "        for e in range(len(all_stock_dict[r][\"日期\"])):\n",
    "            #print(avai_date_list[u],all_stock_dict[r][\"日期\"][e])\n",
    "            if avai_date_list[u] == all_stock_dict[r][\"日期\"][e]:\n",
    "                #print(1)\n",
    "                date = avai_date_list[u]\n",
    "                date_stock_dict[date][r]['成交股數'] = str(all_stock_dict[r]['成交股數'][e])\n",
    "                date_stock_dict[date][r]['開盤價'] = str(all_stock_dict[r]['開盤價'][e])\n",
    "                date_stock_dict[date][r]['收盤價'] = str(all_stock_dict[r]['收盤價'][e])\n",
    "                date_stock_dict[date][r]['漲跌價差'] = str(all_stock_dict[r]['漲跌價差'][e])\n",
    "                date_stock_dict[date][r]['成交筆數'] = str(all_stock_dict[r]['成交筆數'][e])\n",
    "                #date_stock_dict[u]\n",
    "# print(date_stock_dict['2019-03-10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這次的專案中，我們希望透過etf看到全台、各產業別受到中美貿易戰的影響程度，因此台灣股市資料中，我們優先選取指數型etf如元大台灣50和富邦各類別的交易資訊，並加入各產業中具有代表性的企業。\n",
    "爬取證交所，找取'元大台商0054','元大電子0053','富邦科技0052','富邦金融0059','台積電2330','鴻海2317','南亞1303','台塑1301','國泰金2882'的\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, csv\n",
    "import re\n",
    "import time\n",
    "from xlwt import *\n",
    "import sys\n",
    "import requests, json, csv, datetime\n",
    "from xlrd import *\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "#import xlwt\n",
    "#import xlwt\n",
    "#指定file以utf-8的格式打开\n",
    "col = 0\n",
    "row = 1\n",
    "m = 0\n",
    "stock_name_list = ['元大台商0054','元大電子0053','富邦科技0052','富邦金融0059','台積電2330','鴻海2317','南亞1303','台塑1301','國泰金2882']\n",
    "stock_num_list = ['0054','0053','0052','0059','2330','2317','1303','1301','2882']\n",
    "year_count_list = ['2018']\n",
    "month_count_list = ['06','07','08','09','10','11','12']\n",
    "spe_2019_month_count_list = ['01','02','03','04','05']\n",
    "fields = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "for y in range(1,len(stock_num_list)):\n",
    "    row = 1\n",
    "    file = Workbook(encoding = 'utf-8')\n",
    "    table = file.add_sheet(str(stock_name_list[y]), cell_overwrite_ok=True)\n",
    "    stock_num = stock_num_list[y]\n",
    "    for m in range(9):\n",
    "        table.write(row,m,fields[m])\n",
    "    transaction_amount = []\n",
    "    total_data_list = []\n",
    "    change_list = []\n",
    "    date_list = []\n",
    "    for year_count in year_count_list:\n",
    "        for month_count in month_count_list:\n",
    "            time.sleep(6)\n",
    "            url_twse = 'http://www.tse.com.tw/exchangeReport/STOCK_DAY?response=json&date=' + str(year_count) + str(month_count) +  '01&stockNo='+ str(stock_num) + '&_=1533353379536'\n",
    "            res = requests.get(url_twse)\n",
    "            s = json.loads(res.text)\n",
    "            if s['stat'] == \"OK\":\n",
    "                for data in (s['data']):\n",
    "                    row += 1\n",
    "                    total_data_list.append(data)\n",
    "                    #change_list.append(data[7])\n",
    "                    if \",\" in data[8]:\n",
    "                        data[8] = data[8].replace(\",\",\"\")\n",
    "                        #transaction_amount.append(float(data[8]))\n",
    "                    else:\n",
    "                        transaction_amount.append(float(data[8]))\n",
    "                        #date_list.append(data[0])\n",
    "                    for j in range(9):\n",
    "                        table.write(row,j,data[j])\n",
    "            #print(stock_num,year_count,month_count)\n",
    "    for month_count in spe_2019_month_count_list:\n",
    "        time.sleep(6)\n",
    "        url_twse = 'http://www.tse.com.tw/exchangeReport/STOCK_DAY?response=json&date=2019'+ str(month_count) +  '01&stockNo='+ str(stock_num) + '&_=1533353379536'\n",
    "        res = requests.get(url_twse)\n",
    "        s = json.loads(res.text)\n",
    "        if s['stat'] == \"OK\":\n",
    "            for data in (s['data']):\n",
    "                row += 1\n",
    "                total_data_list.append(data)\n",
    "                #change_list.append(data[7])\n",
    "                if \",\" in data[8]:\n",
    "                    data[8] = data[8].replace(\",\",\"\")\n",
    "                        #transaction_amount.append(float(data[8]))\n",
    "                else:\n",
    "                    transaction_amount.append(float(data[8]))\n",
    "                        #date_list.append(data[0])\n",
    "                for j in range(9):\n",
    "                    table.write(row,j,data[j])\n",
    "        #print(stock_num,'2019',month_count)\n",
    "    file_name = 'C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\個股資料'+stock_name_list[y]+'.csv'\n",
    "    #file_name = 'C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\個股資料.csv'\n",
    "    file.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  High         Low        Open       Close     Volume  \\\n",
      "Date                                                                    \n",
      "2016-05-31  110.760002  110.360001  110.410004  110.699997  3368800.0   \n",
      "2016-06-01  110.650002  110.410004  110.589996  110.419998  2941300.0   \n",
      "2016-06-02  110.739998  110.559998  110.559998  110.699997  1909400.0   \n",
      "2016-06-03  111.300003  111.120003  111.150002  111.300003  2210500.0   \n",
      "2016-06-06  111.230003  111.070000  111.169998  111.150002  3278900.0   \n",
      "2016-06-07  111.309998  111.199997  111.239998  111.250000  2157100.0   \n",
      "2016-06-08  111.339996  111.220001  111.300003  111.290001  2148000.0   \n",
      "2016-06-09  111.500000  111.360001  111.500000  111.370003  1543600.0   \n",
      "2016-06-10  111.660004  111.449997  111.540001  111.519997  1368300.0   \n",
      "2016-06-13  111.669998  111.529999  111.570000  111.610001  1661400.0   \n",
      "2016-06-14  111.730003  111.550003  111.680000  111.559998  1871500.0   \n",
      "2016-06-15  111.930000  111.639999  111.669998  111.800003  1732100.0   \n",
      "2016-06-16  112.070000  111.779999  111.919998  111.870003  2533000.0   \n",
      "2016-06-17  111.870003  111.660004  111.860001  111.790001  2730900.0   \n",
      "2016-06-20  111.580002  111.449997  111.570000  111.480003  2043800.0   \n",
      "2016-06-21  111.570000  111.349998  111.550003  111.400002  1882500.0   \n",
      "2016-06-22  111.510002  111.349998  111.440002  111.470001  1734300.0   \n",
      "2016-06-23  111.430000  111.250000  111.330002  111.279999  1721100.0   \n",
      "2016-06-24  112.150002  111.790001  112.110001  111.879997  4081200.0   \n",
      "2016-06-27  112.489998  112.309998  112.330002  112.330002  3018800.0   \n",
      "2016-06-28  112.540001  112.370003  112.540001  112.470001  2951700.0   \n",
      "2016-06-29  112.599998  112.339996  112.529999  112.389999  2745800.0   \n",
      "2016-06-30  112.690002  112.400002  112.510002  112.620003  4154300.0   \n",
      "2016-07-01  112.769997  112.519997  112.720001  112.650002  5235200.0   \n",
      "2016-07-05  113.120003  112.870003  113.029999  112.949997  4740000.0   \n",
      "2016-07-06  113.169998  112.940002  113.089996  113.160004  3150500.0   \n",
      "2016-07-07  113.169998  112.919998  113.000000  113.080002  3113700.0   \n",
      "2016-07-08  113.269997  113.000000  113.080002  113.250000  2910500.0   \n",
      "2016-07-11  113.239998  112.930000  113.190002  112.949997  4424000.0   \n",
      "2016-07-12  112.809998  112.489998  112.809998  112.610001  1970600.0   \n",
      "...                ...         ...         ...         ...        ...   \n",
      "2019-04-23  108.279999  108.150002  108.180000  108.250000  3422700.0   \n",
      "2019-04-24  108.529999  108.419998  108.419998  108.500000  3000000.0   \n",
      "2019-04-25  108.550003  108.419998  108.470001  108.489998  2648100.0   \n",
      "2019-04-26  108.750000  108.660004  108.739998  108.709999  2299900.0   \n",
      "2019-04-29  108.620003  108.489998  108.559998  108.519997  2782600.0   \n",
      "2019-04-30  108.680000  108.510002  108.559998  108.589996  7491500.0   \n",
      "2019-05-01  108.760002  108.320000  108.470001  108.400002  6387900.0   \n",
      "2019-05-02  108.330002  108.099998  108.330002  108.160004  3379400.0   \n",
      "2019-05-03  108.419998  108.279999  108.320000  108.339996  2326300.0   \n",
      "2019-05-06  108.570000  108.440002  108.559998  108.480003  4609100.0   \n",
      "2019-05-07  108.699997  108.589996  108.629997  108.610001  3051400.0   \n",
      "2019-05-08  108.809998  108.550003  108.739998  108.589996  5946400.0   \n",
      "2019-05-09  108.809998  108.550003  108.779999  108.650002  4847600.0   \n",
      "2019-05-10  108.820000  108.629997  108.739998  108.669998  5257500.0   \n",
      "2019-05-13  108.980003  108.820000  108.830002  108.849998  6733800.0   \n",
      "2019-05-14  108.970001  108.870003  108.900002  108.940002  6217000.0   \n",
      "2019-05-15  109.180000  109.000000  109.160004  109.129997  2666500.0   \n",
      "2019-05-16  109.040001  108.949997  109.040001  109.000000  2757000.0   \n",
      "2019-05-17  109.150002  108.940002  109.120003  109.029999  2090800.0   \n",
      "2019-05-20  109.059998  108.860001  108.980003  108.879997  2035000.0   \n",
      "2019-05-21  108.910004  108.809998  108.860001  108.870003  2029800.0   \n",
      "2019-05-22  109.089996  108.919998  108.949997  109.050003  3509900.0   \n",
      "2019-05-23  109.500000  109.139999  109.180000  109.370003  4922500.0   \n",
      "2019-05-24  109.449997  109.330002  109.370003  109.410004  2010300.0   \n",
      "2019-05-28  109.650002  109.500000  109.570000  109.570000  6270100.0   \n",
      "2019-05-29  109.849998  109.599998  109.730003  109.599998  5634400.0   \n",
      "2019-05-30  109.940002  109.650002  109.769997  109.889999  3305200.0   \n",
      "2019-05-31  110.639999  110.000000  110.010002  110.400002  9204100.0   \n",
      "2019-06-03  110.519997  110.169998  110.260002  110.400002  7137500.0   \n",
      "2019-06-04  110.379997  110.129997  110.279999  110.300003  5131700.0   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2016-05-31  102.173912  \n",
      "2016-06-01  102.116722  \n",
      "2016-06-02  102.375679  \n",
      "2016-06-03  102.930542  \n",
      "2016-06-06  102.791817  \n",
      "2016-06-07  102.884308  \n",
      "2016-06-08  102.921280  \n",
      "2016-06-09  102.995270  \n",
      "2016-06-10  103.133995  \n",
      "2016-06-13  103.217224  \n",
      "2016-06-14  103.170998  \n",
      "2016-06-15  103.392937  \n",
      "2016-06-16  103.457687  \n",
      "2016-06-17  103.383690  \n",
      "2016-06-20  103.097000  \n",
      "2016-06-21  103.023026  \n",
      "2016-06-22  103.087761  \n",
      "2016-06-23  102.912025  \n",
      "2016-06-24  103.466927  \n",
      "2016-06-27  103.883095  \n",
      "2016-06-28  104.012558  \n",
      "2016-06-29  103.938576  \n",
      "2016-06-30  104.151291  \n",
      "2016-07-01  104.375961  \n",
      "2016-07-05  104.653900  \n",
      "2016-07-06  104.848488  \n",
      "2016-07-07  104.774345  \n",
      "2016-07-08  104.931870  \n",
      "2016-07-11  104.653900  \n",
      "2016-07-12  104.338905  \n",
      "...                ...  \n",
      "2019-04-23  107.736488  \n",
      "2019-04-24  107.985298  \n",
      "2019-04-25  107.975342  \n",
      "2019-04-26  108.194305  \n",
      "2019-04-29  108.005203  \n",
      "2019-04-30  108.074875  \n",
      "2019-05-01  108.144707  \n",
      "2019-05-02  107.905273  \n",
      "2019-05-03  108.084846  \n",
      "2019-05-06  108.224525  \n",
      "2019-05-07  108.354210  \n",
      "2019-05-08  108.334259  \n",
      "2019-05-09  108.394119  \n",
      "2019-05-10  108.414070  \n",
      "2019-05-13  108.593643  \n",
      "2019-05-14  108.683441  \n",
      "2019-05-15  108.872986  \n",
      "2019-05-16  108.743294  \n",
      "2019-05-17  108.773224  \n",
      "2019-05-20  108.623573  \n",
      "2019-05-21  108.613602  \n",
      "2019-05-22  108.793182  \n",
      "2019-05-23  109.112427  \n",
      "2019-05-24  109.152328  \n",
      "2019-05-28  109.311951  \n",
      "2019-05-29  109.341881  \n",
      "2019-05-30  109.631195  \n",
      "2019-05-31  110.139999  \n",
      "2019-06-03  110.400002  \n",
      "2019-06-04  110.300003  \n",
      "\n",
      "[758 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('美國etf_AGG.pickle', 'rb') as file:\n",
    "    a_dict1 =pickle.load(file)\n",
    "print(a_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0054': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '0053': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '0052': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '0059': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '2330': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '1303': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '1301': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '2882': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}, '2317': {'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}}\n",
      "{'日期': [], '成交股數': [], '成交金額': [], '開盤價': [], '最高價': [], '最低價': [], '收盤價': [], '漲跌價差': [], '成交筆數': []}\n"
     ]
    }
   ],
   "source": [
    "#-----------------將台灣股市excel 取入資料 再變成pickle\n",
    "import xlrd\n",
    "import pickle\n",
    "stock_name_list = ['元大台商0054','元大電子0053','富邦科技0052','富邦金融0059','台積電2330','南亞1303','台塑1301','國泰金2882','鴻海2317']\n",
    "stock_num_list = ['0054','0053','0052','0059','2330','1303','1301','2882','2317']\n",
    "all_stock_d = {}\n",
    "t_l = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "adr_l  =[]\n",
    "for y in range(len(stock_num_list)):\n",
    "    adr_l.append('C:\\\\Users\\\\Will\\\\Desktop\\datascience_upload\\\\股票資料\\\\個股資料'+stock_name_list[y]+\".csv\")\n",
    "    all_stock_d[stock_num_list[y]] = {}\n",
    "    for i in range(len(t_l)):\n",
    "        all_stock_d[stock_num_list[y]][t_l[i]]= []\n",
    "stock_data_2882= all_stock_d['2882']\n",
    "print(all_stock_d)\n",
    "print(stock_data_2882)\n",
    "for i in range(len(stock_num_list)):\n",
    "    if stock_num_list[i] == '2317':\n",
    "        file_r = adr_l[i]\n",
    "        book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "        sheet_1 = book_r.sheet_by_index(0)\n",
    "        for b in range(len(t_l)):\n",
    "            for r in range(1,240):\n",
    "                if sheet_1.cell_value(rowx=r,colx=0) != \"\":\n",
    "                    all_stock_d[stock_num_list[i]][t_l[b]].append(sheet_1.cell_value(rowx=r,colx=b))\n",
    "                else:\n",
    "                    break\n",
    "    else:\n",
    "        file_r = adr_l[i]\n",
    "        book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "        sheet_1 = book_r.sheet_by_index(0)\n",
    "        for b in range(len(t_l)):\n",
    "            for r in range(1,246):\n",
    "                if sheet_1.cell_value(rowx=r,colx=0) != \"\":\n",
    "                    all_stock_d[stock_num_list[i]][t_l[b]].append(sheet_1.cell_value(rowx=r,colx=b))\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "#-------------將台灣股市excel變成pickle 存成pickle\n",
    "stock_name_list = ['元大台商0054','元大電子0053','富邦科技0052','富邦金融0059','台積電2330','鴻海2317','南亞1303','台塑1301','國泰金2882']\n",
    "stock_num_list = ['0054','0053','0052','0059','2330','2317','1303','1301','2882']\n",
    "for i in range(len(stock_name_list)):\n",
    "    file_name = '股票資料'+stock_name_list[i]+'.pickle'\n",
    "    file = open(file_name, 'wb')\n",
    "    pickle.dump(all_stock_d[stock_num_list[i]], file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30,000', '25,000', '4,000', '17,000', '121,000', '14,000', '17,000', '10,000', '8,090', '7,000', '6,000', '11,000', '11,000', '6,000', '13,000', '10,000', '10,000', '48,000', '9,000', '25,000', '10,000', '23,000', '2,000', '29,000', '28,000', '71,000', '22,000', '43,000', '12,000', '31,000', '27,000', '6,000', '19,000', '1,000', '43,000', '35,000', '72,000', '12,000', '21,000', '21,000', '14,000', '42,000', '13,000', '27,000', '5,000', '19,000', '11,000', '5,000', '2,000', '3,000', '45,000', '11,000', '12,000', '15,000', '11,000', '9,000', '4,000', '2,000', '9,000', '2,000', '37,000', '12,000', '17,000', '17,000', '11,000', '28,000', '31,072', '16,000', '7,000', '18,000', '21,000', '11,000', '13,000', '9,075', '5,000', '11,000', '17,000', '4,000', '13,000', '7,000', '14,000', '9,074', '11,000', '14,000', '5,000', '20,000', '4,075', '18,000', '7,000', '28,000', '6,000', '36,000', '45,000', '8,083', '18,000', '9,000', '3,000', '16,000', '7,000', '13,083', '5,000', '7,000', '22,000', '19,000', '4,010', '31,000', '5,000', '42,000', '4,010', '10,000', '8,000', '1,000', '24,000', '7,000', '12,000', '2,000', '2,000', '8,000', '5,000', '3,000', '3,000', '7,000', '1,000', '12,000', '7,000', '11,000', '7,000', '2,000', '6,000', '3,000', '2,000', '10,000', '8,000', '11,000', '2,000', '2,000', '4,000', '1,000', '18,000', '4,000', '3,000', '2,000', '24,000', '3,000', '9,000', '19,000', '5,000', '4,000', '1,000']\n"
     ]
    }
   ],
   "source": [
    "print(all_stock_d[stock_num_list[1]][t_l[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pickle\n",
    "t_l = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\datascience_upload\\\\股票資料\\\\ETF0050.csv'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "all_stock_d={}\n",
    "for i in range(len(t_l)):\n",
    "        all_stock_d[t_l[i]]= []\n",
    "for b in range(len(t_l)):\n",
    "    for r in range(246):\n",
    "        if sheet_1.cell_value(rowx=r,colx=0) != \"\":\n",
    "            all_stock_d[t_l[b]].append(sheet_1.cell_value(rowx=r,colx=b))\n",
    "        else:\n",
    "            break\n",
    "file_name = '股票資料ETF0050.pickle'\n",
    "file = open(file_name, 'wb')\n",
    "pickle.dump(all_stock_d, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------資料整理 從個股資料pickle中取出資訊 整理成容易操作的儲存方式\n",
    "import pickle\n",
    "stock_name_list = ['元大台商0054','元大電子0053','富邦科技0052','富邦金融0059','台積電2330','鴻海2317','南亞1303','台塑1301','國泰金2882']\n",
    "stock_num_list = ['0054','0053','0052','0059','2330','2317','1303','1301','2882']\n",
    "adr_l = []\n",
    "all_stock_dict = {}\n",
    "for y in range(len(stock_name_list)):\n",
    "    adr_l.append('C:\\\\Users\\\\Will\\\\Desktop\\datascience_upload\\\\股票資料'+stock_name_list[y]+\".pickle\")\n",
    "for i in range(len(stock_name_list)):\n",
    "    with open(adr_l[i], 'rb') as file:\n",
    "        a_dict1 =pickle.load(file)\n",
    "        all_stock_dict[stock_num_list[i]] = a_dict1\n",
    "    #print(adr_l[i])\n",
    "print(all_stock_dict['0059'])\n",
    "# with open('C:\\\\Users\\\\Will\\\\Desktop\\datascience_upload\\\\股票資料\\\\美國etf_SPY.pickle', 'rb') as file:\n",
    "#     a_dict1 =pickle.load(file)\n",
    "# print(adr_l[i])\n",
    "# print(a_dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出情緒分數中，缺少那些天數?並整理成日期對應的分數dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import datetime,time\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\每日情緒分數.xlsx'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "emotion_date_list = []\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "for i in range(313):\n",
    "    date = datetime.datetime.utcfromtimestamp((sheet_1.cell_value(rowx=i,colx=0)-25569)*86400)\n",
    "    date = date.strftime('%Y-%m-%d')\n",
    "    emotion_date_list.append(date)\n",
    "print(emotion_date_list)\n",
    "#print(sheet_1.cell_value(rowx=1,colx=0))\n",
    "#print(datetime.datetime.utcfromtimestamp((sheet_1.cell_value(rowx=0,colx=0)-25569)*86400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "將各股資料與情緒分數和日期結合，因為某些日期並不會有股市資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "#------------根據情緒分數清單，製作時間dict \n",
    "#{'2018-07-07': {'emotion_score': 4.0, '0054': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0053': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0052': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0059': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2330': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '1303': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '1301': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2882': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2317': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}}, \n",
    "import xlrd\n",
    "import datetime,time\n",
    "avai_date_list = []\n",
    "file_r = 'C:\\\\Users\\\\Will\\\\Desktop\\\\情緒分數.xlsx'\n",
    "book_r = xlrd.open_workbook(file_r,encoding_override=\"utf-8\")\n",
    "sheet_1 = book_r.sheet_by_index(0)\n",
    "start='2018-07-02'\n",
    "end='2019-06-05'\n",
    "date_stock_dict = {}\n",
    "non_exsit_date_stock_dict = {} #沒有情緒分數\n",
    "datestart=datetime.datetime.strptime(start,'%Y-%m-%d')\n",
    "dateend=datetime.datetime.strptime(end,'%Y-%m-%d')\n",
    "stock_num_list = ['0054','0053','0052','0059','2330','1303','1301','2882','2317']\n",
    "t_l = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "while datestart<dateend:\n",
    "    datestart+=datetime.timedelta(days=1)\n",
    "    date = datestart.strftime('%Y-%m-%d')\n",
    "    if date in emotion_date_list:\n",
    "        for i in range(1,327):\n",
    "            date1 = datetime.datetime.utcfromtimestamp((sheet_1.cell_value(rowx=i,colx=0)-25569)*86400)\n",
    "            date1 = date1.strftime('%Y-%m-%d')\n",
    "            if date ==date1:\n",
    "                avai_date_list.append(date)\n",
    "                date_stock_dict[date] = {'emotion_score':float(sheet_1.cell_value(rowx=i,colx=1))}\n",
    "                for u in stock_num_list:\n",
    "                    date_stock_dict[date][u] = {\"成交股數\":'0',\"開盤價\":'0',\"收盤價\":'0',\"漲跌價差\":'0',\"成交筆數\":'0'}\n",
    "    else:\n",
    "        non_exsit_date_stock_dict[date] = {}\n",
    "print(len(avai_date_list))\n",
    "# print(date[-1],date[-2],type(date[-3]))\n",
    "# print(date_stock_dict)\n",
    "print(len(date_stock_dict))\n",
    "# print(non_exsit_date_stock_dict)\n",
    "# print(len(non_exsit_date_stock_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-----------------將股市資料放置配對日期\n",
    "#{'2018-07-07': {'emotion_score': 4.0, '0054': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0053': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0052': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '0059': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2330': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '1303': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '1301': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2882': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}, '2317': {'成交股數': 0, '開盤價': 0, '收盤價': 0, '漲跌價差': 0, '成交筆數': 0}}, \n",
    "stock_num_list = ['0054','0053','0052','0059','2330','2317','1303','1301','2882']\n",
    "#all_stock_dict['0059']\n",
    "t_l = [\"日期\",\"成交股數\",\"成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"漲跌價差\",\"成交筆數\"]\n",
    "for r in stock_num_list:\n",
    "    for u in range(len(all_stock_dict[r][\"日期\"])):\n",
    "        all_stock_dict[r][\"日期\"][u] = str(all_stock_dict[r][\"日期\"][u]).replace('/','-',2)\n",
    "        all_stock_dict[r][\"日期\"][u] = str(all_stock_dict[r][\"日期\"][u]).replace('107','2018')\n",
    "        all_stock_dict[r][\"日期\"][u] = str(all_stock_dict[r][\"日期\"][u]).replace('108','2019')\n",
    "        #print(all_stock_dict[r][\"日期\"][u])\n",
    "for r in stock_num_list:\n",
    "    for u in range(len(avai_date_list)):\n",
    "        for e in range(len(all_stock_dict[r][\"日期\"])):\n",
    "            print(avai_date_list[u],all_stock_dict[r][\"日期\"][e])\n",
    "            if avai_date_list[u] == all_stock_dict[r][\"日期\"][e]:\n",
    "                print(1)\n",
    "                date = avai_date_list[u]\n",
    "                date_stock_dict[date][r]['成交股數'] = str(all_stock_dict[r]['成交股數'][e])\n",
    "                date_stock_dict[date][r]['開盤價'] = str(all_stock_dict[r]['開盤價'][e])\n",
    "                date_stock_dict[date][r]['收盤價'] = str(all_stock_dict[r]['收盤價'][e])\n",
    "                date_stock_dict[date][r]['漲跌價差'] = str(all_stock_dict[r]['漲跌價差'][e])\n",
    "                date_stock_dict[date][r]['成交筆數'] = str(all_stock_dict[r]['成交筆數'][e])\n",
    "                #date_stock_dict[u]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = '情緒分數與台灣股票資料.pickle'\n",
    "file = open(file_name, 'wb')\n",
    "pickle.dump(date_stock_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'2019-05-23': {'emotion_score': -25.0, '0054': {'成交股數': '8,000', '開盤價': '20.92', '收盤價': '20.67', '漲跌價差': '-0.32', '成交筆數': '8'}, '0053': {'成交股數': '3,000', '開盤價': '32.26', '收盤價': '32.24', '漲跌價差': '-0.87', '成交筆數': '3'}, '0052': {'成交股數': '112,223', '開盤價': '50.35', '收盤價': '49.79', '漲跌價差': '-1.46', '成交筆數': '17'}, '0059': {'成交股數': '3,000', '開盤價': '44.58', '收盤價': '44.59', '漲跌價差': '-0.03', '成交筆數': '3'}, '2330': {'成交股數': '62,258,627', '開盤價': '233.50', '收盤價': '230.00', '漲跌價差': '-8.00', '成交筆數': '24974'}, '1303': {'成交股數': '4,500,407', '開盤價': '77.90', '收盤價': '77.90', '漲跌價差': '+0.40', '成交筆數': '1465'}, '1301': {'成交股數': '6,230,424', '開盤價': '109.50', '收盤價': '109.00', '漲跌價差': '-1.00', '成交筆數': '2971'}, '2882': {'成交股數': '12,965,650', '開盤價': '41.00', '收盤價': '41.00', '漲跌價差': '-0.15', '成交筆數': '5521'}, '2317': {'成交股數': '63,692,307', '開盤價': '72.70', '收盤價': '71.50', '漲跌價差': '-2.50', '成交筆數': '28490'}}, '2019-05-24': {'emotion_score': -16.0, '0054': {'成交股數': '8,000', '開盤價': '20.76', '收盤價': '20.63', '漲跌價差': '-0.04', '成交筆數': '4'}, '0053': {'成交股數': '3,000', '開盤價': '32.26', '收盤價': '32.26', '漲跌價差': '+0.02', '成交筆數': '3'}, '0052': {'成交股數': '101,200', '開盤價': '49.83', '收盤價': '50.00', '漲跌價差': '+0.21', '成交筆數': '6'}, '0059': {'成交股數': '3,000', '開盤價': '44.60', '收盤價': '44.65', '漲跌價差': '+0.06', '成交筆數': '3'}, '2330': {'成交股數': '38,226,789', '開盤價': '230.00', '收盤價': '233.00', '漲跌價差': '+3.00', '成交筆數': '14586'}, '1303': {'成交股數': '4,580,386', '開盤價': '77.90', '收盤價': '77.60', '漲跌價差': '-0.30', '成交筆數': '1435'}, '1301': {'成交股數': '5,782,632', '開盤價': '107.50', '收盤價': '108.50', '漲跌價差': '-0.50', '成交筆數': '2736'}, '2882': {'成交股數': '18,894,722', '開盤價': '41.00', '收盤價': '40.60', '漲跌價差': '-0.40', '成交筆數': '8160'}, '2317': {'成交股數': '40,844,359', '開盤價': '71.50', '收盤價': '71.40', '漲跌價差': '-0.10', '成交筆數': '18744'}}, '2019-05-25': {'emotion_score': 7.0, '0054': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '0053': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '0052': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '0059': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '2330': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '1303': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '1301': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '2882': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '2317': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}}, '2019-05-26': {'emotion_score': 25.0, '0054': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '0053': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '0052': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '0059': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '2330': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '1303': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '1301': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '2882': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}, '2317': {'成交股數': '0', '開盤價': '0', '收盤價': '0', '漲跌價差': '0', '成交筆數': '0'}}, '2019-05-27': {'emotion_score': -7.0, '0054': {'成交股數': '2,000', '開盤價': '20.63', '收盤價': '20.57', '漲跌價差': '-0.06', '成交筆數': '2'}, '0053': {'成交股數': '8,053', '開盤價': '32.11', '收盤價': '32.04', '漲跌價差': '-0.22', '成交筆數': '6'}, '0052': {'成交股數': '109,060', '開盤價': '50.20', '收盤價': '49.83', '漲跌價差': '-0.17', '成交筆數': '13'}, '0059': {'成交股數': '2,000', '開盤價': '44.88', '收盤價': '44.88', '漲跌價差': '+0.23', '成交筆數': '2'}, '2330': {'成交股數': '37,447,033', '開盤價': '234.00', '收盤價': '231.00', '漲跌價差': '-2.00', '成交筆數': '13895'}, '1303': {'成交股數': '4,928,017', '開盤價': '78.00', '收盤價': '78.40', '漲跌價差': '+0.80', '成交筆數': '1512'}, '1301': {'成交股數': '2,586,670', '開盤價': '108.50', '收盤價': '109.50', '漲跌價差': '+1.00', '成交筆數': '1406'}, '2882': {'成交股數': '9,377,954', '開盤價': '40.65', '收盤價': '40.75', '漲跌價差': '+0.15', '成交筆數': '3864'}, '2317': {'成交股數': '25,409,320', '開盤價': '71.60', '收盤價': '71.40', '漲跌價差': ' 0.00', '成交筆數': '11329'}}, '2019-05-28': {'emotion_score': 4.0, '0054': {'成交股數': '4,000', '開盤價': '20.70', '收盤價': '20.69', '漲跌價差': '+0.12', '成交筆數': '3'}, '0053': {'成交股數': '24,000', '開盤價': '32.04', '收盤價': '32.14', '漲跌價差': '+0.10', '成交筆數': '8'}, '0052': {'成交股數': '104,417', '開盤價': '49.81', '收盤價': '49.69', '漲跌價差': '-0.14', '成交筆數': '8'}, '0059': {'成交股數': '44,000', '開盤價': '44.80', '收盤價': '44.59', '漲跌價差': '-0.29', '成交筆數': '8'}, '2330': {'成交股數': '99,322,033', '開盤價': '232.00', '收盤價': '230.50', '漲跌價差': '-0.50', '成交筆數': '10122'}, '1303': {'成交股數': '16,827,035', '開盤價': '78.40', '收盤價': '78.40', '漲跌價差': ' 0.00', '成交筆數': '1689'}, '1301': {'成交股數': '12,643,810', '開盤價': '109.50', '收盤價': '110.00', '漲跌價差': '+0.50', '成交筆數': '2180'}, '2882': {'成交股數': '87,709,120', '開盤價': '40.75', '收盤價': '40.35', '漲跌價差': '-0.40', '成交筆數': '6088'}, '2317': {'成交股數': '138,134,091', '開盤價': '71.30', '收盤價': '71.20', '漲跌價差': '-0.20', '成交筆數': '14561'}}, '2019-05-29': {'emotion_score': -17.0, '0054': {'成交股數': '10,000', '開盤價': '20.52', '收盤價': '20.68', '漲跌價差': '-0.01', '成交筆數': '5'}, '0053': {'成交股數': '4,000', '開盤價': '31.88', '收盤價': '32.02', '漲跌價差': '-0.12', '成交筆數': '3'}, '0052': {'成交股數': '136,000', '開盤價': '49.05', '收盤價': '49.29', '漲跌價差': '-0.40', '成交筆數': '10'}, '0059': {'成交股數': '78,000', '開盤價': '44.69', '收盤價': '44.61', '漲跌價差': '+0.02', '成交筆數': '7'}, '2330': {'成交股數': '32,260,236', '開盤價': '228.00', '收盤價': '229.50', '漲跌價差': '-1.00', '成交筆數': '10233'}, '1303': {'成交股數': '6,880,079', '開盤價': '77.30', '收盤價': '77.50', '漲跌價差': '-0.90', '成交筆數': '2057'}, '1301': {'成交股數': '5,111,320', '開盤價': '110.00', '收盤價': '109.00', '漲跌價差': '-1.00', '成交筆數': '3183'}, '2882': {'成交股數': '13,430,157', '開盤價': '40.35', '收盤價': '40.30', '漲跌價差': '-0.05', '成交筆數': '5035'}, '2317': {'成交股數': '43,871,336', '開盤價': '70.20', '收盤價': '72.20', '漲跌價差': '+1.00', '成交筆數': '19856'}}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
